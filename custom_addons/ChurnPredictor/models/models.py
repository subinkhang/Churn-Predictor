# -*- coding: utf-8 -*-
import base64
import json # <<< TH√äM M·ªöI
import requests # <<< TH√äM M·ªöI
import logging # <<< TH√äM M·ªöI
import markdown2 # <<< TH√äM M·ªöI

from odoo import models, fields, api, _ # <<< TH√äM _
from odoo.exceptions import UserError # <<< TH√äM M·ªöI

_logger = logging.getLogger(__name__)

class ChurnPrediction(models.Model):
    """
    Model n√†y d√πng ƒë·ªÉ l∆∞u tr·ªØ k·∫øt qu·∫£ c·ªßa m·ªói l·∫ßn d·ª± ƒëo√°n churn.
    M·ªói b·∫£n ghi (record) trong model n√†y t∆∞∆°ng ·ª©ng v·ªõi m·ªôt l·∫ßn ch·∫°y d·ª± ƒëo√°n
    cho m·ªôt kh√°ch h√†ng t·∫°i m·ªôt th·ªùi ƒëi·ªÉm c·ª• th·ªÉ.
    """
    _name = 'churn.prediction'
    _description = 'Customer Churn Prediction Result'
    _order = 'prediction_date desc' # S·∫Øp x·∫øp m·∫∑c ƒë·ªãnh theo ng√†y d·ª± ƒëo√°n m·ªõi nh·∫•t

    # --- C√°c tr∆∞·ªùng (Fields) ch√≠nh c·ªßa Model ---

    # M·ªëi quan h·ªá Many2one: M·ªói k·∫øt qu·∫£ d·ª± ƒëo√°n thu·ªôc v·ªÅ M·ªòT kh√°ch h√†ng.
    # 'res.partner' l√† model m·∫∑c ƒë·ªãnh c·ªßa Odoo ƒë·ªÉ qu·∫£n l√Ω li√™n h·ªá (kh√°ch h√†ng, nh√† cung c·∫•p...).
    customer_id = fields.Many2one(
        'res.partner',
        string='Customer',
        required=True,
        ondelete='cascade', # N·∫øu kh√°ch h√†ng b·ªã x√≥a, k·∫øt qu·∫£ d·ª± ƒëo√°n li√™n quan c≈©ng b·ªã x√≥a.
        help="The customer for whom the prediction was made."
    )

    # Ng√†y v√† gi·ªù th·ª±c hi·ªán d·ª± ƒëo√°n. M·∫∑c ƒë·ªãnh l√† th·ªùi ƒëi·ªÉm t·∫°o b·∫£n ghi.
    prediction_date = fields.Datetime(
        string='Prediction Date',
        required=True,
        default=fields.Datetime.now,
        readonly=True,
        help="Date and time when the prediction was generated."
    )

    # K·∫øt qu·∫£ d·ª± ƒëo√°n (d·∫°ng l·ª±a ch·ªçn).
    prediction_result = fields.Selection(
        [
            ('churn', 'Churn'),
            ('no_churn', 'No Churn')
        ],
        string='Prediction Result',
        required=False,
        help="The outcome predicted by the model (Churn or No Churn)."
    )

    # X√°c su·∫•t kh√°ch h√†ng s·∫Ω r·ªùi b·ªè (t·ª´ 0.0 ƒë·∫øn 100.0).
    probability = fields.Float(
        string='Churn Probability (%)',
        digits=(16, 2), # Hi·ªÉn th·ªã v·ªõi 2 ch·ªØ s·ªë th·∫≠p ph√¢n.
        help="The probability (from 0 to 100) that the customer will churn, as calculated by the model."
    )

    # Tr∆∞·ªùng HTML ƒë·ªÉ l∆∞u v√† hi·ªÉn th·ªã bi·ªÉu ƒë·ªì gi·∫£i th√≠ch t·ª´ SHAP.
    # Ch√∫ng ta s·∫Ω l∆∞u tr·ª±c ti·∫øp m√£ HTML c·ªßa bi·ªÉu ƒë·ªì v√†o ƒë√¢y.
    shap_html = fields.Binary(
        string='Prediction Explanation (SHAP Data)',
        readonly=True
    )
    # Tr∆∞·ªùng Text ƒë·ªÉ l∆∞u d·ªØ li·ªáu SHAP th√¥ d·∫°ng JSON.
    # D·ªØ li·ªáu n√†y s·∫Ω ƒë∆∞·ª£c g·ª≠i t·ªõi AI ƒë·ªÉ di·ªÖn gi·∫£i.
    shap_data_json = fields.Text(
        string='SHAP Raw Data (JSON)',
        readonly=True,
        help="Raw SHAP data (base value, feature values, SHAP values) stored in JSON format, used for generating AI explanations."
    )

    shap_ai_explanation = fields.Text(
        string='AI-Powered Explanation',
        readonly=True,
        help="The natural language explanation of the prediction, generated by an AI service."
    )

    # Th√™m m·ªôt tr∆∞·ªùng ƒë·ªÉ hi·ªÉn th·ªã t√™n kh√°ch h√†ng cho ti·ªán l·ª£i
    # related='customer_id.name' s·∫Ω t·ª± ƒë·ªông l·∫•y gi√° tr·ªã t·ª´ tr∆∞·ªùng 'name' c·ªßa model 'res.partner'
    customer_name = fields.Char(
        string="Customer Name",
        related='customer_id.name',
        readonly=True,
        store=True # L∆∞u v√†o DB ƒë·ªÉ c√≥ th·ªÉ t√¨m ki·∫øm/nh√≥m theo t√™n
    )
    
    churn_rate = fields.Float(
        string="Churn Rate",
        compute='_compute_churn_rate',
        store=True, # store=True l√† b·∫Øt bu·ªôc ƒë·ªÉ c√≥ th·ªÉ group by v√† t√≠nh to√°n tr√™n view
        group_operator='avg', # Ch·ªâ ƒë·ªãnh c√°ch Odoo t·ªïng h·ª£p tr∆∞·ªùng n√†y
    )    
    
    customer_state_id = fields.Many2one(
        'res.country.state', 
        string='Customer State',
        related='customer_id.state_id',
        store=True, # B·∫Øt bu·ªôc ph·∫£i c√≥ store=True ƒë·ªÉ c√≥ th·ªÉ group_by
        readonly=True,
    )
    
    probability_level = fields.Selection(
        [
            ('low', 'Low Risk (0-30%)'),
            ('medium', 'Medium Risk (30-70%)'),
            ('high', 'High Risk (70-100%)')
        ],
        string="Probability Level",
        compute='_compute_probability_level',
        store=True, # B·∫Øt bu·ªôc ph·∫£i c√≥ store=True ƒë·ªÉ c√≥ th·ªÉ group_by
    )
    
    is_high_risk = fields.Integer(
        string="Is High Risk",
        compute='_compute_is_high_risk',
        store=True, # B·∫Øt bu·ªôc ƒë·ªÉ c√≥ th·ªÉ t√≠nh to√°n tr√™n view
        default=0,
    )
    
    product_count = fields.Integer(
        string="Number of Products Purchased",
        default=1, # Ho·∫∑c m·ªôt gi√° tr·ªã m·∫∑c ƒë·ªãnh h·ª£p l√Ω
        help="The number of distinct products the customer has purchased."
    )

    @api.depends('probability_level')
    def _compute_is_high_risk(self):
        """
        G√°n gi√° tr·ªã 1 n·∫øu l√† 'high', ng∆∞·ª£c l·∫°i l√† 0.
        Vi·ªác t√≠nh t·ªïng (sum) c·ªßa tr∆∞·ªùng n√†y s·∫Ω cho ra s·ªë kh√°ch h√†ng nguy c∆° cao.
        """
        for record in self:
            if record.probability_level == 'high':
                record.is_high_risk = 1
            else:
                record.is_high_risk = 0

    @api.depends('probability')
    def _compute_probability_level(self):
        """
        T·ª± ƒë·ªông ph√¢n lo·∫°i m·ª©c ƒë·ªô r·ªßi ro d·ª±a tr√™n x√°c su·∫•t churn.
        """
        for record in self:
            if record.probability < 30:
                record.probability_level = 'low'
            elif record.probability < 70:
                record.probability_level = 'medium'
            else:
                record.probability_level = 'high'

    @api.depends('prediction_result')
    def _compute_churn_rate(self):
        """
        Tr∆∞·ªùng n√†y tr·∫£ v·ªÅ 100 n·∫øu l√† churn, 0 n·∫øu kh√¥ng.
        Khi t√≠nh trung b√¨nh (avg) tr√™n view, n√≥ s·∫Ω ra ƒë√∫ng t·ª∑ l·ªá %.
        """
        for record in self:
            if record.prediction_result == 'churn':
                record.churn_rate = 100.0
            else:
                record.churn_rate = 0.0
                
    @api.model
    def get_dashboard_kpis(self, domain=None):
        """
        H√†m n√†y ƒë∆∞·ª£c g·ªçi t·ª´ JavaScript ƒë·ªÉ l·∫•y d·ªØ li·ªáu cho c√°c √¥ KPI.
        N√≥ ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p ƒë·ªÉ ch·∫•p nh·∫≠n m·ªôt `domain` ƒë·ªÉ l·ªçc d·ªØ li·ªáu.
        """
        # N·∫øu kh√¥ng c√≥ domain ƒë∆∞·ª£c truy·ªÅn v√†o, s·ª≠ d·ª•ng m·ªôt domain tr·ªëng (l·∫•y t·∫•t c·∫£)
        if domain is None:
            domain = []
            
        # ƒê·ªçc d·ªØ li·ªáu t·ª´ c√°c b·∫£n ghi d·ª± ƒëo√°n ƒë√£ ƒë∆∞·ª£c l·ªçc
        predictions = self.search_read(
            domain,
            ['is_high_risk', 'probability', 'churn_rate']
        )
        
        # L·∫•y t·ªïng s·ªë b·∫£n ghi d·ª± ƒëo√°n (tr∆∞·ªõc khi l·ªçc) ƒë·ªÉ t√≠nh t·ª∑ l·ªá %
        total_predictions_overall = self.search_count([])

        total_predictions_in_group = len(predictions)
        high_risk_customers = sum(p['is_high_risk'] for p in predictions)
        
        # T√≠nh to√°n ƒë·ªÉ tr√°nh l·ªói chia cho 0
        average_churn_probability = 0
        overall_churn_rate = 0
        high_risk_percentage = 0

        if total_predictions_in_group > 0:
            average_churn_probability = sum(p['probability'] for p in predictions) / total_predictions_in_group
            overall_churn_rate = sum(p['churn_rate'] for p in predictions) / total_predictions_in_group
        
        if total_predictions_overall > 0:
            # T·ª∑ l·ªá % kh√°ch h√†ng r·ªßi ro cao c·ªßa nh√≥m hi·ªán t·∫°i so v·ªõi T·ªîNG S·ªê
            high_risk_percentage = (high_risk_customers / total_predictions_overall) * 100

        return {
            'total_predictions': total_predictions_in_group,
            'high_risk_customers': high_risk_customers,
            'average_churn_probability': round(average_churn_probability, 2),
            'overall_churn_rate': round(overall_churn_rate, 2),
            'high_risk_percentage': round(high_risk_percentage, 1), # D·ªØ li·ªáu cho progress bar
        }
        
    def action_generate_ai_explanation(self):
        """
        [UPDATED v3] ƒê∆∞·ª£c g·ªçi b·ªüi n√∫t "Explain with AI".
        N√¢ng c·∫•p: B·ªï sung Context (Category & FULL Timeline History).
        """
        self.ensure_one()
        
        _logger.info(">>> [AI XAI] B·∫Øt ƒë·∫ßu action_generate_ai_explanation cho prediction ID: %d", self.id)

        # --- B∆Ø·ªöC 1: L·∫§Y C·∫§U H√åNH ---
        config_param = self.env['ir.config_parameter'].sudo()
        api_key = config_param.get_param('churn_predictor.google_ai_api_key')
        api_endpoint = config_param.get_param('churn_predictor.google_ai_endpoint')

        if not api_key or not api_endpoint:
            raise UserError(_("AI Service is not configured."))
        
        if not self.shap_data_json:
            raise UserError(_("No SHAP data available. Please run prediction first."))

        # --- B∆Ø·ªöC 2: CHU·∫®N B·ªä D·ªÆ LI·ªÜU SHAP ---
        try:
            shap_data = json.loads(self.shap_data_json)
        except json.JSONDecodeError:
            raise UserError(_("Could not read the SHAP data."))

        feature_impacts = sorted(
            zip(shap_data['feature_names'], shap_data['shap_values'], shap_data['feature_values']),
            key=lambda x: abs(x[1]),
            reverse=True
        )
        
        # --- [NEW] B∆Ø·ªöC 2.1: L·∫§Y D·ªÆ LI·ªÜU B·ªêI C·∫¢NH (CONTEXT DATA) ---
        _logger.info(">>> ƒêang thu th·∫≠p d·ªØ li·ªáu b·ªëi c·∫£nh kh√°ch h√†ng...")

        # 1. L·∫•y Product Category
        raw_category = self.customer_id.x_feat_product_category_name_english_last or "Unknown"
        customer_category = raw_category.replace('_', ' ').title()

        # 2. L·∫•y L·ªãch s·ª≠ t∆∞∆°ng t√°c (TIMELINE HISTORY)
        history_log = ""
        try:
            # G·ªçi h√†m l·∫•y timeline t·ª´ res.partner
            timeline_data = self.customer_id.get_interaction_timeline_data(self.customer_id.id)
            timeline_list = timeline_data.get('timeline', [])
            
            if timeline_list:
                # L·∫•y t·ªëi ƒëa 10 s·ª± ki·ªán g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh qu√° t·∫£i Token
                # timeline_list ƒë√£ ƒë∆∞·ª£c sort ng∆∞·ª£c (m·ªõi nh·∫•t ƒë·∫ßu ti√™n) t·ª´ h√†m g·ªëc
                recent_events = timeline_list[:10] 
                
                log_lines = []
                for event in recent_events:
                    # Format: "- 2023-12-01 [Email]: Ti√™u ƒë·ªÅ - N·ªôi dung ng·∫Øn"
                    # C·∫Øt ng·∫Øn description n·∫øu qu√° d√†i (> 100 k√Ω t·ª±) ƒë·ªÉ ti·∫øt ki·ªám token
                    desc = event['description']
                    if len(desc) > 100:
                        desc = desc[:100] + "..."
                        
                    line = f"- {event['date']} [{event['channel']}]: {event['title']} - {desc}"
                    log_lines.append(line)
                
                history_log = "\n".join(log_lines)
                _logger.info(">>> ƒê√£ l·∫•y %d s·ª± ki·ªán l·ªãch s·ª≠ g·∫ßn nh·∫•t.", len(recent_events))
            else:
                history_log = "Ch∆∞a c√≥ l·ªãch s·ª≠ t∆∞∆°ng t√°c n√†o."
                _logger.info(">>> Kh√°ch h√†ng ch∆∞a c√≥ t∆∞∆°ng t√°c n√†o trong timeline.")
                
        except Exception as e:
            _logger.warning(">>> L·ªói khi l·∫•y l·ªãch s·ª≠ t∆∞∆°ng t√°c: %s", str(e))
            history_log = "Kh√¥ng th·ªÉ truy xu·∫•t l·ªãch s·ª≠ t∆∞∆°ng t√°c."

        # --- B∆Ø·ªöC 2.2: X·ª¨ L√ù TEXT SHAP ---
        top_n = 7
        features_description = ""
        count = 0
        for name, shap_val, feature_val in feature_impacts[:top_n]:
            if count >= top_n: break
            if name.startswith('bert_') or name.startswith('tfidf_'): continue
            
            direction = "tƒÉng" if shap_val > 0 else "gi·∫£m"
            features_description += f"- {name} = {feature_val:.2f}: l√†m {direction} nguy c∆° churn (ƒë·ªô m·∫°nh: {shap_val:.4f})\n"
            count += 1

        prediction_summary = "R·ªúI B·ªé (Churn)" if self.prediction_result == 'churn' else "·ªû L·∫†I (No Churn)"

        # --- B∆Ø·ªöC 3: X√ÇY D·ª∞NG PROMPT N√ÇNG C·∫§P ---
        # ƒê√£ c·∫≠p nh·∫≠t ph·∫ßn Timeline History
        
        prompt = f"""
        **Vai tr√≤:** B·∫°n l√† chuy√™n gia ph√¢n t√≠ch tr·∫£i nghi·ªám kh√°ch h√†ng (CX Analyst). H√£y vi·∫øt b√°o c√°o ph√¢n t√≠ch r·ªßi ro b·∫±ng ti·∫øng Vi·ªát (Markdown).

        **1. H·ªì s∆° Kh√°ch h√†ng (Context):**
        - **Ng√†nh h√†ng quan t√¢m:** {customer_category}
        - **D√≤ng th·ªùi gian t∆∞∆°ng t√°c (M·ªõi nh·∫•t tr∆∞·ªõc):**
        {history_log}

        **2. K·∫øt qu·∫£ D·ª± b√°o AI:**
        - **D·ª± ƒëo√°n:** {prediction_summary}
        - **X√°c su·∫•t:** {self.probability:.2f}%
        
        **3. Ph√¢n t√≠ch D·ªØ li·ªáu K·ªπ thu·∫≠t (SHAP Values):**
        {features_description}

        ---
        **Y√™u c·∫ßu ƒë·∫ßu ra (Output Format):**
        
        **K·∫øt lu·∫≠n:** [ƒê√°nh gi√° t·ªïng quan v·ªÅ t√¨nh tr·∫°ng kh√°ch h√†ng d·ª±a tr√™n c·∫£ L·ªãch s·ª≠ t∆∞∆°ng t√°c v√† Ch·ªâ s·ªë d·ª± b√°o].

        **üî¥ R·ªßi ro & V·∫•n ƒë·ªÅ:**
        - **[T√™n v·∫•n ƒë·ªÅ]:** [Gi·∫£i th√≠ch ng·∫Øn g·ªçn].
        
        **üü¢ ƒêi·ªÉm t√≠ch c·ª±c:**
        - **[T√™n ƒëi·ªÉm t·ªët]:** [Gi·∫£i th√≠ch ng·∫Øn g·ªçn].

        **üí° H√†nh ƒë·ªông ƒë·ªÅ xu·∫•t:**
        - [D·ª±a tr√™n l·ªãch s·ª≠ t∆∞∆°ng t√°c (v√≠ d·ª•: n·∫øu c√≥ ph√†n n√†n/tr·∫£ h√†ng) v√† ng√†nh h√†ng {customer_category}, h√£y ƒë·ªÅ xu·∫•t 1 h√†nh ƒë·ªông c·ª• th·ªÉ cho Sales/CSKH ƒë·ªÉ gi·ªØ ch√¢n kh√°ch].

        **L∆∞u √Ω quan tr·ªçng:** 
        - H√£y ƒë·ªçc k·ªπ "D√≤ng th·ªùi gian t∆∞∆°ng t√°c". N·∫øu th·∫•y kh√°ch h√†ng c√≥ ph√†n n√†n, khi·∫øu n·∫°i ho·∫∑c tr·∫£ h√†ng g·∫ßn ƒë√¢y, h√£y coi ƒë√≥ l√† nguy√™n nh√¢n ch√≠nh d·∫´n ƒë·∫øn Churn v√† c·∫£nh b√°o ngay.
        """
        
        # --- B∆Ø·ªöC 4: G·ªåI API (C·∫•u h√¨nh Max Token & Safety) ---
        headers = {'Content-Type': 'application/json'}
        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": 0.7, 
                "maxOutputTokens": 4096 
            },
            "safetySettings": [
                { "category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE" },
                { "category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE" },
                { "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE" },
                { "category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE" }
            ]
        }
        
        try:
            # _logger.info(">>> Prompt g·ª≠i ƒëi (Debug): %s", prompt) # Uncomment n·∫øu mu·ªën xem prompt
            response = requests.post(
                f"{api_endpoint}?key={api_key}", 
                headers=headers, 
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            response_data = response.json()
            
            # X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ (bao g·ªìm c·∫£ tr∆∞·ªùng h·ª£p MAX_TOKENS)
            if 'candidates' in response_data and response_data['candidates']:
                candidate = response_data['candidates'][0]
                finish_reason = candidate.get('finishReason')
                
                valid_reasons = ['STOP', 'MAX_TOKENS']
                if finish_reason and finish_reason not in valid_reasons:
                    raise UserError(_("AI refused to generate explanation. Reason: %s", finish_reason))
                
                if 'content' in candidate and 'parts' in candidate['content']:
                    raw_explanation_md = candidate['content']['parts'][0]['text']
                else:
                    raise UserError(_("AI response structure is invalid."))
            else:
                raise UserError(_("AI returned an empty response."))

            html_explanation = markdown2.markdown(raw_explanation_md)
            
            if finish_reason == 'MAX_TOKENS':
                html_explanation += "<p><em>(K·∫øt qu·∫£ b·ªã c·∫Øt ng·∫Øn do gi·ªõi h·∫°n ƒë·ªô d√†i.)</em></p>"

            self.write({
                'shap_ai_explanation': html_explanation
            })
            _logger.info(">>> ƒê√£ l∆∞u k·∫øt qu·∫£ XAI (bao g·ªìm l·ªãch s·ª≠ t∆∞∆°ng t√°c) th√†nh c√¥ng.")

        except requests.exceptions.RequestException as e:
            _logger.error("L·ªói k·∫øt n·ªëi API: %s", e)
            raise UserError(_("Connection Error: %s", str(e)))
        except Exception as e:
            _logger.error("L·ªói h·ªá th·ªëng: %s", e)
            raise UserError(_("System Error: %s", str(e)))

        return True

    def action_view_shap_logs(self):
        """
        H√†m in log ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p ƒë·ªÉ LO·∫†I B·ªé c√°c feature 'bert_'
        """
        self.ensure_one()
        _logger.info(">>> B·∫Øt ƒë·∫ßu in log SHAP cho Prediction ID: %d", self.id)

        if not self.shap_data_json:
            raise UserError(_("Kh√¥ng c√≥ d·ªØ li·ªáu SHAP ƒë·ªÉ ph√¢n t√≠ch."))

        try:
            shap_data = json.loads(self.shap_data_json)
        except json.JSONDecodeError:
            raise UserError(_("D·ªØ li·ªáu SHAP b·ªã l·ªói JSON."))

        # 1. S·∫Øp x·∫øp d·ªØ li·ªáu
        feature_impacts = sorted(
            zip(shap_data['feature_names'], shap_data['shap_values'], shap_data['feature_values']),
            key=lambda x: abs(x[1]),
            reverse=True
        )

        # ==============================================================================
        # IN B·∫¢NG LOG (ƒê√É L·ªåC BERT)
        # ==============================================================================
        debug_msg = ["\n" + "‚ñí" * 90]
        debug_msg.append(f" üïµÔ∏è [MANUAL CHECK] B·∫¢NG PH√ÇN T√çCH SHAP LOGS (NO BERT)")
        debug_msg.append(f" Customer: {self.customer_name} | Probability: {self.probability:.2f}%")
        debug_msg.append("‚ñí" * 90)
        debug_msg.append(f"{'RANK':<5} | {'FEATURE NAME':<45} | {'VALUE':<12} | {'IMPACT':<10} | {'EFFECT'}")
        debug_msg.append("-" * 90)

        # Bi·∫øn ƒë·∫øm th·ª© h·∫°ng hi·ªÉn th·ªã (v√¨ i s·∫Ω b·ªã nh·∫£y c√≥c khi skip bert)
        display_rank = 1

        for name, shap_val, feature_val in feature_impacts:
            # === ƒêO·∫†N QUAN TR·ªåNG: L·ªåC B·ªé BERT ===
            if name.startswith('bert_') or name.startswith('tfidf_'): 
                continue 
            # ====================================

            direction = "TƒÇNG üî¥" if shap_val > 0 else "GI·∫¢M üü¢"
            
            # C·∫Øt ng·∫Øn t√™n n·∫øu qu√° d√†i ƒë·ªÉ b·∫£ng ƒë·∫πp h∆°n
            display_name = (name[:42] + '..') if len(name) > 42 else name
            
            line = f"#{display_rank:02d}   | {display_name:<45} | {feature_val:>10.2f}   | {shap_val:>10.4f}   | {direction}"
            debug_msg.append(line)
            display_rank += 1
            
        debug_msg.append("=" * 90 + "\n")
        _logger.info("\n".join(debug_msg))

        return {
            'type': 'ir.actions.client',
            'tag': 'display_notification',
            'params': {
                'title': 'Check Docker Logs',
                'message': 'ƒê√£ in b·∫£ng ph√¢n t√≠ch (ƒë√£ l·ªçc b·ªè Bert) ra terminal.',
                'type': 'success',
                'sticky': False,
            }
        }
