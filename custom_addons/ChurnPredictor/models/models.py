# -*- coding: utf-8 -*-
import base64
import json # <<< THÃŠM Má»šI
import requests # <<< THÃŠM Má»šI
import logging # <<< THÃŠM Má»šI
import markdown2 # <<< THÃŠM Má»šI

from odoo import models, fields, api, _ # <<< THÃŠM _
from odoo.exceptions import UserError # <<< THÃŠM Má»šI

_logger = logging.getLogger(__name__)

class ChurnPrediction(models.Model):
    """
    Model nÃ y dÃ¹ng Ä‘á»ƒ lÆ°u trá»¯ káº¿t quáº£ cá»§a má»—i láº§n dá»± Ä‘oÃ¡n churn.
    Má»—i báº£n ghi (record) trong model nÃ y tÆ°Æ¡ng á»©ng vá»›i má»™t láº§n cháº¡y dá»± Ä‘oÃ¡n
    cho má»™t khÃ¡ch hÃ ng táº¡i má»™t thá»i Ä‘iá»ƒm cá»¥ thá»ƒ.
    """
    _name = 'churn.prediction'
    _description = 'Customer Churn Prediction Result'
    _order = 'prediction_date desc' # Sáº¯p xáº¿p máº·c Ä‘á»‹nh theo ngÃ y dá»± Ä‘oÃ¡n má»›i nháº¥t

    # --- CÃ¡c trÆ°á»ng (Fields) chÃ­nh cá»§a Model ---

    # Má»‘i quan há»‡ Many2one: Má»—i káº¿t quáº£ dá»± Ä‘oÃ¡n thuá»™c vá» Má»˜T khÃ¡ch hÃ ng.
    # 'res.partner' lÃ  model máº·c Ä‘á»‹nh cá»§a Odoo Ä‘á»ƒ quáº£n lÃ½ liÃªn há»‡ (khÃ¡ch hÃ ng, nhÃ  cung cáº¥p...).
    customer_id = fields.Many2one(
        'res.partner',
        string='Customer',
        required=True,
        ondelete='cascade', # Náº¿u khÃ¡ch hÃ ng bá»‹ xÃ³a, káº¿t quáº£ dá»± Ä‘oÃ¡n liÃªn quan cÅ©ng bá»‹ xÃ³a.
        help="The customer for whom the prediction was made."
    )

    # NgÃ y vÃ  giá» thá»±c hiá»‡n dá»± Ä‘oÃ¡n. Máº·c Ä‘á»‹nh lÃ  thá»i Ä‘iá»ƒm táº¡o báº£n ghi.
    prediction_date = fields.Datetime(
        string='Prediction Date',
        required=True,
        default=fields.Datetime.now,
        readonly=True,
        help="Date and time when the prediction was generated."
    )

    # Káº¿t quáº£ dá»± Ä‘oÃ¡n (dáº¡ng lá»±a chá»n).
    prediction_result = fields.Selection(
        [
            ('churn', 'Churn'),
            ('no_churn', 'No Churn')
        ],
        string='Prediction Result',
        required=False,
        help="The outcome predicted by the model (Churn or No Churn)."
    )

    # XÃ¡c suáº¥t khÃ¡ch hÃ ng sáº½ rá»i bá» (tá»« 0.0 Ä‘áº¿n 100.0).
    probability = fields.Float(
        string='Churn Probability (%)',
        digits=(16, 2), # Hiá»ƒn thá»‹ vá»›i 2 chá»¯ sá»‘ tháº­p phÃ¢n.
        help="The probability (from 0 to 100) that the customer will churn, as calculated by the model."
    )

    # TrÆ°á»ng HTML Ä‘á»ƒ lÆ°u vÃ  hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ giáº£i thÃ­ch tá»« SHAP.
    # ChÃºng ta sáº½ lÆ°u trá»±c tiáº¿p mÃ£ HTML cá»§a biá»ƒu Ä‘á»“ vÃ o Ä‘Ã¢y.
    shap_html = fields.Binary(
        string='Prediction Explanation (SHAP Data)',
        readonly=True
    )
    # TrÆ°á»ng Text Ä‘á»ƒ lÆ°u dá»¯ liá»‡u SHAP thÃ´ dáº¡ng JSON.
    # Dá»¯ liá»‡u nÃ y sáº½ Ä‘Æ°á»£c gá»­i tá»›i AI Ä‘á»ƒ diá»…n giáº£i.
    shap_data_json = fields.Text(
        string='SHAP Raw Data (JSON)',
        readonly=True,
        help="Raw SHAP data (base value, feature values, SHAP values) stored in JSON format, used for generating AI explanations."
    )

    shap_ai_explanation = fields.Text(
        string='AI-Powered Explanation',
        readonly=True,
        help="The natural language explanation of the prediction, generated by an AI service."
    )

    # ThÃªm má»™t trÆ°á»ng Ä‘á»ƒ hiá»ƒn thá»‹ tÃªn khÃ¡ch hÃ ng cho tiá»‡n lá»£i
    # related='customer_id.name' sáº½ tá»± Ä‘á»™ng láº¥y giÃ¡ trá»‹ tá»« trÆ°á»ng 'name' cá»§a model 'res.partner'
    customer_name = fields.Char(
        string="Customer Name",
        related='customer_id.name',
        readonly=True,
        store=True # LÆ°u vÃ o DB Ä‘á»ƒ cÃ³ thá»ƒ tÃ¬m kiáº¿m/nhÃ³m theo tÃªn
    )
    
    churn_rate = fields.Float(
        string="Churn Rate",
        compute='_compute_churn_rate',
        store=True, # store=True lÃ  báº¯t buá»™c Ä‘á»ƒ cÃ³ thá»ƒ group by vÃ  tÃ­nh toÃ¡n trÃªn view
        group_operator='avg', # Chá»‰ Ä‘á»‹nh cÃ¡ch Odoo tá»•ng há»£p trÆ°á»ng nÃ y
    )    
    
    customer_state_id = fields.Many2one(
        'res.country.state', 
        string='Customer State',
        related='customer_id.state_id',
        store=True, # Báº¯t buá»™c pháº£i cÃ³ store=True Ä‘á»ƒ cÃ³ thá»ƒ group_by
        readonly=True,
    )
    
    probability_level = fields.Selection(
        [
            ('low', 'Low Risk (0-30%)'),
            ('medium', 'Medium Risk (30-70%)'),
            ('high', 'High Risk (70-100%)')
        ],
        string="Probability Level",
        compute='_compute_probability_level',
        store=True, # Báº¯t buá»™c pháº£i cÃ³ store=True Ä‘á»ƒ cÃ³ thá»ƒ group_by
    )
    
    is_high_risk = fields.Integer(
        string="Is High Risk",
        compute='_compute_is_high_risk',
        store=True, # Báº¯t buá»™c Ä‘á»ƒ cÃ³ thá»ƒ tÃ­nh toÃ¡n trÃªn view
        default=0,
    )
    
    product_count = fields.Integer(
        string="Number of Products Purchased",
        default=1, # Hoáº·c má»™t giÃ¡ trá»‹ máº·c Ä‘á»‹nh há»£p lÃ½
        help="The number of distinct products the customer has purchased."
    )

    @api.depends('probability_level')
    def _compute_is_high_risk(self):
        """
        GÃ¡n giÃ¡ trá»‹ 1 náº¿u lÃ  'high', ngÆ°á»£c láº¡i lÃ  0.
        Viá»‡c tÃ­nh tá»•ng (sum) cá»§a trÆ°á»ng nÃ y sáº½ cho ra sá»‘ khÃ¡ch hÃ ng nguy cÆ¡ cao.
        """
        for record in self:
            if record.probability_level == 'high':
                record.is_high_risk = 1
            else:
                record.is_high_risk = 0

    @api.depends('probability')
    def _compute_probability_level(self):
        """
        Tá»± Ä‘á»™ng phÃ¢n loáº¡i má»©c Ä‘á»™ rá»§i ro dá»±a trÃªn xÃ¡c suáº¥t churn.
        """
        for record in self:
            if record.probability < 30:
                record.probability_level = 'low'
            elif record.probability < 70:
                record.probability_level = 'medium'
            else:
                record.probability_level = 'high'

    @api.depends('prediction_result')
    def _compute_churn_rate(self):
        """
        TrÆ°á»ng nÃ y tráº£ vá» 100 náº¿u lÃ  churn, 0 náº¿u khÃ´ng.
        Khi tÃ­nh trung bÃ¬nh (avg) trÃªn view, nÃ³ sáº½ ra Ä‘Ãºng tá»· lá»‡ %.
        """
        for record in self:
            if record.prediction_result == 'churn':
                record.churn_rate = 100.0
            else:
                record.churn_rate = 0.0
                
    @api.model
    def get_dashboard_kpis(self, domain=None):
        """
        HÃ m nÃ y Ä‘Æ°á»£c gá»i tá»« JavaScript Ä‘á»ƒ láº¥y dá»¯ liá»‡u cho cÃ¡c Ã´ KPI.
        NÃ³ Ä‘Ã£ Ä‘Æ°á»£c nÃ¢ng cáº¥p Ä‘á»ƒ cháº¥p nháº­n má»™t `domain` Ä‘á»ƒ lá»c dá»¯ liá»‡u.
        """
        # Náº¿u khÃ´ng cÃ³ domain Ä‘Æ°á»£c truyá»n vÃ o, sá»­ dá»¥ng má»™t domain trá»‘ng (láº¥y táº¥t cáº£)
        if domain is None:
            domain = []
            
        # Äá»c dá»¯ liá»‡u tá»« cÃ¡c báº£n ghi dá»± Ä‘oÃ¡n Ä‘Ã£ Ä‘Æ°á»£c lá»c
        predictions = self.search_read(
            domain,
            ['is_high_risk', 'probability', 'churn_rate']
        )
        
        # Láº¥y tá»•ng sá»‘ báº£n ghi dá»± Ä‘oÃ¡n (trÆ°á»›c khi lá»c) Ä‘á»ƒ tÃ­nh tá»· lá»‡ %
        total_predictions_overall = self.search_count([])

        total_predictions_in_group = len(predictions)
        high_risk_customers = sum(p['is_high_risk'] for p in predictions)
        
        # TÃ­nh toÃ¡n Ä‘á»ƒ trÃ¡nh lá»—i chia cho 0
        average_churn_probability = 0
        overall_churn_rate = 0
        high_risk_percentage = 0

        if total_predictions_in_group > 0:
            average_churn_probability = sum(p['probability'] for p in predictions) / total_predictions_in_group
            overall_churn_rate = sum(p['churn_rate'] for p in predictions) / total_predictions_in_group
        
        if total_predictions_overall > 0:
            # Tá»· lá»‡ % khÃ¡ch hÃ ng rá»§i ro cao cá»§a nhÃ³m hiá»‡n táº¡i so vá»›i Tá»”NG Sá»
            high_risk_percentage = (high_risk_customers / total_predictions_overall) * 100

        return {
            'total_predictions': total_predictions_in_group,
            'high_risk_customers': high_risk_customers,
            'average_churn_probability': round(average_churn_probability, 2),
            'overall_churn_rate': round(overall_churn_rate, 2),
            'high_risk_percentage': round(high_risk_percentage, 1), # Dá»¯ liá»‡u cho progress bar
        }
        
        
    def action_generate_ai_explanation(self):
        """
        ÄÆ°á»£c gá»i bá»Ÿi nÃºt "Explain with AI".
        HÃ m nÃ y láº¥y dá»¯ liá»‡u SHAP thÃ´, gá»­i Ä‘áº¿n API cá»§a Google AI vÃ  lÆ°u láº¡i lá»i giáº£i thÃ­ch.
        """
        self.ensure_one()
        
        # <<< DEBUG LOG 1: Kiá»ƒm tra xem hÃ m cÃ³ Ä‘Æ°á»£c gá»i khÃ´ng >>>
        _logger.info(">>> Báº¯t Ä‘áº§u action_generate_ai_explanation cho prediction ID: %d", self.id)

        # --- BÆ¯á»šC 1: Láº¤Y Cáº¤U HÃŒNH ---
        config_param = self.env['ir.config_parameter'].sudo()
        api_key = config_param.get_param('churn_predictor.google_ai_api_key')
        api_endpoint = config_param.get_param('churn_predictor.google_ai_endpoint')

        if not api_key or not api_endpoint:
            raise UserError(_("AI Service is not configured. Please contact your system administrator to set the API Key and Endpoint in the system parameters."))
        
        # <<< DEBUG LOG 2: Kiá»ƒm tra ná»™i dung cá»§a trÆ°á»ng shap_data_json >>>
        _logger.info("Kiá»ƒm tra dá»¯ liá»‡u SHAP...")
        _logger.info("Ná»™i dung trÆ°á»ng shap_data_json: %s", self.shap_data_json)

        if not self.shap_data_json:
            _logger.warning("Lá»—i: Dá»¯ liá»‡u SHAP (shap_data_json) rá»—ng hoáº·c khÃ´ng há»£p lá»‡.")
            raise UserError(_("No SHAP data available to generate an explanation. Please try running the prediction again for this customer."))

        # --- BÆ¯á»šC 2: CHUáº¨N Bá»Š Dá»® LIá»†U VÃ€ PROMPT ---
        try:
            shap_data = json.loads(self.shap_data_json)
            # <<< DEBUG LOG 3: Dá»¯ liá»‡u SHAP sau khi Ä‘Æ°á»£c parse >>>
            _logger.info("PhÃ¢n tÃ­ch JSON tá»« shap_data_json thÃ nh cÃ´ng.")
            _logger.debug("Dá»¯ liá»‡u SHAP Ä‘Ã£ Ä‘Æ°á»£c parse: %s", shap_data)
        except json.JSONDecodeError:
            _logger.error("Lá»—i phÃ¢n tÃ­ch JSON tá»« trÆ°á»ng shap_data_json.")
            raise UserError(_("Could not read the SHAP data. It might be corrupted."))

        feature_impacts = sorted(
            zip(shap_data['feature_names'], shap_data['shap_values'], shap_data['feature_values']),
            key=lambda x: abs(x[1]),
            reverse=True
        )
        
        # TiÃªu Ä‘á» báº£ng
        debug_msg = ["\n" + "â–’" * 90]
        debug_msg.append(f" ğŸ•µï¸ [FULL CHECK] Báº¢NG PHÃ‚N TÃCH Táº¤T Cáº¢ {len(feature_impacts)} FEATURES")
        debug_msg.append(f" Customer: {self.customer_name} | Probability: {self.probability:.2f}%")
        debug_msg.append("â–’" * 90)
        debug_msg.append(f"{'RANK':<5} | {'FEATURE NAME':<40} | {'VALUE':<12} | {'SHAP IMPACT':<12} | {'EFFECT'}")
        debug_msg.append("-" * 90)

        # Duyá»‡t qua TOÃ€N Bá»˜ danh sÃ¡ch (khÃ´ng giá»›i háº¡n top_n)
        for i, (name, shap_val, feature_val) in enumerate(feature_impacts):
            direction = "TÄ‚NG ğŸ”´" if shap_val > 0 else "GIáº¢M ğŸŸ¢"
            # Format dÃ²ng log kiá»ƒu báº£ng
            line = f"#{i+1:02d}   | {name:<40} | {feature_val:>10.2f}   | {shap_val:>10.4f}   | {direction}"
            debug_msg.append(line)
            
        debug_msg.append("=" * 90 + "\n")
        
        # In má»™t láº§n duy nháº¥t Ä‘á»ƒ log liá»n máº¡ch, khÃ´ng bá»‹ Ä‘á»©t Ä‘oáº¡n
        _logger.info("\n".join(debug_msg))
        
        # === Sá»¬A Lá»–I Táº I ÄÃ‚Y ===
        # 1. Chuáº©n bá»‹ má»™t dictionary Ä‘á»ƒ dá»… dÃ ng truy cáº­p giÃ¡ trá»‹ cá»§a feature
        feature_values_dict = dict(zip(shap_data['feature_names'], shap_data['feature_values']))

        # 2. Táº¡o chuá»—i mÃ´ táº£ cÃ¡c feature quan trá»ng nháº¥t
        top_n = 7
        features_description = ""
        count = 0
        
        for name, shap_val, feature_val in feature_impacts[:top_n]:
            if count >= top_n:
                break
                
            # === Lá»ŒC Bá» BERT Äá»‚ AI KHÃ”NG Bá»Š NHIá»„U ===
            if name.startswith('bert_') or name.startswith('tfidf_'):
                continue
            direction = "tÄƒng" if shap_val > 0 else "giáº£m"
            features_description += f"- {name} = {feature_val:.2f}: lÃ m {direction} kháº£ nÄƒng churn (áº£nh hÆ°á»Ÿng: {shap_val:.4f})\n"
            
        # === [START] LOGGING Äáº¸P ===
        # Táº¡o khung viá»n Ä‘á»ƒ dá»… nhÃ¬n tháº¥y trong terminal
        separator = "=" * 60
        sub_separator = "-" * 60
        
        log_content = (
            f"\n{separator}\n"
            f" ğŸ¤– [AI PROMPT PREPARATION] Dá»® LIá»†U SHAP ÄÃƒ ÄÆ N GIáº¢N HÃ“A\n"
            f"{sub_separator}\n"
            f"Prediction ID: {self.id} | Customer: {self.customer_name}\n"
            f"{sub_separator}\n"
            f"{features_description}"  # Biáº¿n nÃ y Ä‘Ã£ cÃ³ sáºµn xuá»‘ng dÃ²ng \n á»Ÿ cuá»‘i má»—i dÃ²ng
            f"{separator}\n"
        )
        
        _logger.info(log_content)
        # === [END] LOGGING Äáº¸P ===

        prediction_summary = "KhÃ¡ch hÃ ng cÃ³ kháº£ nÄƒng Rá»œI Bá» (Churn)" if self.prediction_result == 'churn' else "KhÃ¡ch hÃ ng cÃ³ kháº£ nÄƒng á» Láº I (No Churn)"

        # 3. XÃ¢y dá»±ng Prompt chi tiáº¿t vÃ  an toÃ n
        prompt = f"""
        **Nhiá»‡m vá»¥:** TRá»°C TIáº¾P táº¡o ra má»™t báº£n tÃ³m táº¯t phÃ¢n tÃ­ch churn báº±ng tiáº¿ng Viá»‡t, sá»­ dá»¥ng cÃº phÃ¡p Markdown. KHÃ”NG thÃªm báº¥t ká»³ lá»i dáº«n hay cÃ¢u ná»‘i nÃ o.

        **Bá»‘i cáº£nh:**
        - Káº¿t quáº£: {prediction_summary}, xÃ¡c suáº¥t {self.probability:.2f}%.
        - Dá»¯ liá»‡u áº£nh hÆ°á»Ÿng:
        {features_description}
        ---
        **Äá»‹nh dáº¡ng Ä‘áº§u ra Báº®T BUá»˜C:**

        **Káº¿t luáº­n:** KhÃ¡ch hÃ ng nÃ y cÃ³ **nguy cÆ¡ rá»i bá» cao ({self.probability:.2f}%)**.

        **ğŸ”´ Yáº¿u tá»‘ tiÃªu cá»±c:**
        - **[TÃªn yáº¿u tá»‘ 1] ([GiÃ¡ trá»‹]):** [Giáº£i thÃ­ch Tá»I ÄA Má»˜T CÃ‚U].
        - **[TÃªn yáº¿u tá»‘ 2] ([GiÃ¡ trá»‹]):** [Giáº£i thÃ­ch Tá»I ÄA Má»˜T CÃ‚U].

        **ğŸŸ¢ Yáº¿u tá»‘ tÃ­ch cá»±c:**
        - **[TÃªn yáº¿u tá»‘ 1] ([GiÃ¡ trá»‹]):** [Giáº£i thÃ­ch Tá»I ÄA Má»˜T CÃ‚U].

        **RÃ ng buá»™c:**
        - Chá»‰ sá»­ dá»¥ng cÃ¡c heading Ä‘Ã£ cho: "Káº¿t luáº­n:", "ğŸ”´ Yáº¿u tá»‘ tiÃªu cá»±c:", "ğŸŸ¢ Yáº¿u tá»‘ tÃ­ch cá»±c:".
        - Má»—i gáº¡ch Ä‘áº§u dÃ²ng chá»‰ Ä‘Æ°á»£c phÃ©p dÃ i Tá»I ÄA Má»˜T CÃ‚U.
        - KHÃ”NG thÃªm cÃ¡c phá»ng Ä‘oÃ¡n hoáº·c bÃ¬nh luáº­n dÃ i dÃ²ng khÃ´ng cÃ³ trong dá»¯ liá»‡u.
        """
        # <<< DEBUG LOG 4: Prompt sáº½ Ä‘Æ°á»£c gá»­i Ä‘i >>>
        _logger.info("ÄÃ£ xÃ¢y dá»±ng prompt cho AI.")
        _logger.debug("Prompt (150 kÃ½ tá»± Ä‘áº§u): %s...", prompt[:150].replace('\n', ' '))


        # --- BÆ¯á»šC 3: Gá»ŒI API ---
        headers = {'Content-Type': 'application/json'}
        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {"temperature": 0.7, "maxOutputTokens": 2048}
        }
        
        _logger.info("Chuáº©n bá»‹ gá»­i yÃªu cáº§u tá»›i AI endpoint: %s", api_endpoint)
        try:
            response = requests.post(
                f"{api_endpoint}?key={api_key}", 
                headers=headers, 
                json=payload,
                timeout=30
            )
            response.raise_for_status()

            # <<< DEBUG LOG 5: API gá»i thÃ nh cÃ´ng >>>
            _logger.info("YÃªu cáº§u API thÃ nh cÃ´ng! Status Code: %s", response.status_code)
            
            response_data = response.json()
            
            # TrÃ­ch xuáº¥t ná»™i dung Markdown thÃ´ tá»« AI
            raw_explanation_md = response_data['candidates'][0]['content']['parts'][0]['text']
            _logger.info("ÄÃ£ trÃ­ch xuáº¥t lá»i giáº£i thÃ­ch (Markdown) thÃ nh cÃ´ng.")

            # === BÆ¯á»šC CHUYá»‚N Äá»”I QUAN TRá»ŒNG ===
            # Chuyá»ƒn Ä‘á»•i chuá»—i Markdown sang HTML
            html_explanation = markdown2.markdown(raw_explanation_md)
            _logger.info("ÄÃ£ chuyá»ƒn Ä‘á»•i Markdown sang HTML.")

            # --- BÆ¯á»šC 4: LÆ¯U Káº¾T QUáº¢ (Dáº NG HTML) ---
            self.write({
                'shap_ai_explanation': html_explanation # <<< LÆ°u chuá»—i HTML
            })
            _logger.info("ÄÃ£ lÆ°u lá»i giáº£i thÃ­ch (HTML) cá»§a AI vÃ o prediction ID: %d.", self.id)

        except requests.exceptions.Timeout:
            _logger.error("Lá»—i: YÃªu cáº§u tá»›i AI service bá»‹ timeout.")
            raise UserError(_("The request to the AI service timed out. Please try again later."))
        except requests.exceptions.RequestException as e:
            _logger.error("Lá»—i yÃªu cáº§u API: %s", e)
            _logger.error("Ná»™i dung pháº£n há»“i (náº¿u cÃ³): %s", response.text if 'response' in locals() else 'KhÃ´ng cÃ³ pháº£n há»“i')
            raise UserError(_("An error occurred while communicating with the AI service: %s", str(e)))
        except (KeyError, IndexError) as e:
            _logger.error("Lá»—i phÃ¢n tÃ­ch pháº£n há»“i tá»« AI: %s. Pháº£n há»“i khÃ´ng cÃ³ Ä‘á»‹nh dáº¡ng nhÆ° mong Ä‘á»£i.", e)
            _logger.error("ToÃ n bá»™ pháº£n há»“i tá»« AI: %s", response_data)
            raise UserError(_("The AI service returned an unexpected response format. Please check the logs for more details."))

        return True

    def action_view_shap_logs(self):
        """
        HÃ m in log Ä‘Ã£ Ä‘Æ°á»£c nÃ¢ng cáº¥p Ä‘á»ƒ LOáº I Bá» cÃ¡c feature 'bert_'
        """
        self.ensure_one()
        _logger.info(">>> Báº¯t Ä‘áº§u in log SHAP cho Prediction ID: %d", self.id)

        if not self.shap_data_json:
            raise UserError(_("KhÃ´ng cÃ³ dá»¯ liá»‡u SHAP Ä‘á»ƒ phÃ¢n tÃ­ch."))

        try:
            shap_data = json.loads(self.shap_data_json)
        except json.JSONDecodeError:
            raise UserError(_("Dá»¯ liá»‡u SHAP bá»‹ lá»—i JSON."))

        # 1. Sáº¯p xáº¿p dá»¯ liá»‡u
        feature_impacts = sorted(
            zip(shap_data['feature_names'], shap_data['shap_values'], shap_data['feature_values']),
            key=lambda x: abs(x[1]),
            reverse=True
        )

        # ==============================================================================
        # IN Báº¢NG LOG (ÄÃƒ Lá»ŒC BERT)
        # ==============================================================================
        debug_msg = ["\n" + "â–’" * 90]
        debug_msg.append(f" ğŸ•µï¸ [MANUAL CHECK] Báº¢NG PHÃ‚N TÃCH SHAP LOGS (NO BERT)")
        debug_msg.append(f" Customer: {self.customer_name} | Probability: {self.probability:.2f}%")
        debug_msg.append("â–’" * 90)
        debug_msg.append(f"{'RANK':<5} | {'FEATURE NAME':<45} | {'VALUE':<12} | {'IMPACT':<10} | {'EFFECT'}")
        debug_msg.append("-" * 90)

        # Biáº¿n Ä‘áº¿m thá»© háº¡ng hiá»ƒn thá»‹ (vÃ¬ i sáº½ bá»‹ nháº£y cÃ³c khi skip bert)
        display_rank = 1

        for name, shap_val, feature_val in feature_impacts:
            # === ÄOáº N QUAN TRá»ŒNG: Lá»ŒC Bá» BERT ===
            if name.startswith('bert_') or name.startswith('tfidf_'): 
                continue 
            # ====================================

            direction = "TÄ‚NG ğŸ”´" if shap_val > 0 else "GIáº¢M ğŸŸ¢"
            
            # Cáº¯t ngáº¯n tÃªn náº¿u quÃ¡ dÃ i Ä‘á»ƒ báº£ng Ä‘áº¹p hÆ¡n
            display_name = (name[:42] + '..') if len(name) > 42 else name
            
            line = f"#{display_rank:02d}   | {display_name:<45} | {feature_val:>10.2f}   | {shap_val:>10.4f}   | {direction}"
            debug_msg.append(line)
            display_rank += 1
            
        debug_msg.append("=" * 90 + "\n")
        _logger.info("\n".join(debug_msg))

        return {
            'type': 'ir.actions.client',
            'tag': 'display_notification',
            'params': {
                'title': 'Check Docker Logs',
                'message': 'ÄÃ£ in báº£ng phÃ¢n tÃ­ch (Ä‘Ã£ lá»c bá» Bert) ra terminal.',
                'type': 'success',
                'sticky': False,
            }
        }
